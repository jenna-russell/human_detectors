# Human Detectors

[![arxiv](https://img.shields.io/badge/arXiv-2501.15654-b31b1b.svg)](http://arxiv.org/abs/2501.15654)

This repo hosts `Human Detectors` ([People who frequently use ChatGPT for writing tasks are accurate and robust detectors of AI-generated text](http://arxiv.org/abs/2501.15654)), a dataset of expert annotations of human-written and AI-generated articles. Expert annotations include a decision (Human-written or AI-generated), confidence score, and explanation. We also include the output of many automatic detectors.

`Authors`: Jenna Russell, Marzena Karpinska, Mohit Iyyer

## Introduction
In this paper, we study how well humans can detect text generated by commercial LLMs (GPT-4o, Claude, o1). We hire annotators to read 300 non-fiction English articles, label them as either human-written or AI-generated, and provide paragraph-length explanations for their decisions. Our experiments show that annotators who frequently use LLMs for writing tasks excel at detecting AI-generated text, even without any specialized training or feedback. In fact, the majority vote among five such "expert" annotators misclassifies only 1 of 300 articles, significantly outperforming most commercial and open-source detectors we evaluated even in the presence of evasion tactics like paraphrasing and humanization. Qualitative analysis of the experts' free-form explanations shows that while they rely heavily on specific lexical clues ('AI vocabulary'), they also pick up on more complex phenomena within the text (e.g., formality, originality, clarity) that are challenging to assess for automatic detectors. We release our annotated dataset and code to spur future research into both human and automated detection of AI-generated text.

## Update (January 29th 2025 at 3:24pm)
Please pull the latest version of the repo for an updated version of the dataset. Includes a few fixes to data and introduces a new column for the expert's majority vote answer.

## DATA

Annotation data is stored in a JSON file, formatted as follows:

```markdown
* `generation_model`: (str) - the name of the model which generated the article
* `prompt_id`: (int) - the unique prompt id
* `title`: (str) - original title of the article
* `sub-title`: (str) - original subtitle of the article
* `author`: (str) - author of the original human article
* `source`: (str) - source of the original human article
* `issue`: (str) - publication date of the original human article
* `section`: (str) - thematic section of the original human article
* `link`: (str) - link to the original article
* `article`: (str) - the article used for annotation (human or model-generated depending on the value in `generation_model`)
* `id`: (int) - unique id
* `ground_truth`: (str) - gold label (either "Human-written" or "Machine-generated")
* `pangram`: (str) - detailed output of the pangram detector
* `pangram_humanizers`: (str) - detailed output of the pangram humanizers detector
* `gptzero`: (str) - detailed output of the gptzero detector
* `e5_lora`: (int) - output of the e5_lora detector
* `RADAR`: (int) - output of the radar detector
* `binoculars_lowfpr`: (str) - output of the binoculars detector set to prioritize low fpr
* `bincoulars_accuracy`: (str) - output of the binoculars detector set to prioritize accuracy
* `annotator_1`: (dict) - annotations done by annotator 1
      * `guess`: (str) - label assigned by annotator 1
      * `confidence`: (int) - self-assessed confidence of annotator 1 (5-point scale)
      * `comment`: (str) - justification for their label submitted by annotator 1
* `annotator_2`: (dict) - annotations done by annotator 2
      * `guess`: (str) - label assigned by annotator 2
      * `confidence`: (int) - self-assessed confidence of annotator 2 (5-point scale)
      * `comment`: (str) - justification for their label submitted by annotator 2
* `annotator_3`: (dict) - annotations done by annotator 3
      * `guess`: (str) - label assigned by annotator 3
      * `confidence`: (int) - self-assessed confidence of annotator 3 (5-point scale)
      * `comment`: (str) - justification for their label submitted by annotator 3
* `annotator_4`: (dict) - annotations done by annotator 4
      * `guess`: (str) - label assigned by annotator 4
      * `confidence`: (int) - self-assessed confidence of annotator 4 (5-point scale)
      * `comment`: (str) - justification for their label submitted by annotator 4
* `annotator_5`: (dict) - annotations done by annotator 5
      * `guess`: (str) - label assigned by annotator 5
      * `confidence`: (int) - self-assessed confidence of annotator 5 (5-point scale)
      * `comment`: (str) - justification for their label submitted by annotator 5
* `expert_majority_vote`: (str) - result of the majority vote (at least 3 out of 5 agree)
```

Example entry
```json
{"0":
   {
    "generation_model":"gpt-4o",
    "prompt_id":1,
    "title":"Louisiana schools won't display Ten Commandments before November as lawsuit plays out",
    "sub-title":"Louisiana has agreed to delay implementing a requirement that the Ten Commandments be placed in all of the state\u2019s public school classrooms, at least until November.",
    "author":"Kevin McGill",
    "source":"Associated Press",
    "issue":"7/19/24",
    "section":"Education",
    "link":"https://apnews.com/search?q=Louisiana+schools+won%E2%80%99t+display+Ten+Commandments+before+November+as+lawsuit+plays+out#nt=navsearch",
    "article":"Louisiana won't take official steps to implement a law requiring the Ten ...",
    "id":1,
    "ground_truth":"Human-written",
    "pangram":"pangram_output",
    "pangram_humanizers":"pangram_humanizers_output",
    "gptzero":"gptzero_output",
    "e5_lora":0.0420721397,
    "RADAR":0.8631911874,
    "binoculars_lowfpr":"Most likely human-generated",
    "binoculars_accuracy":"Most likely human-generated",
    "annotator_1":
      {
       "guess":"Human-Generated",
       "confidence":4,
       "comment":"The article overall is very factual and looks quite well-researched. It reads like a standard news story..."
      },
    "annotator_2":
      {
       "guess":"Human-Generated",
       "confidence":4,
       "comment":"I don't see any of the typical words used by AI. Also, the sentences are longer and more complex than..."
      },
    "annotator_3":
      {
       "guess":"Human-Generated",
       "confidence":4,
       "comment":"Some of the phrasing sounds slightly awkward (highlighted), and there're places where the punctuation is off."},
    "annotator_4":
      {
       "guess":"Human-Generated",
       "confidence":5,
       "comment":"The article appears human-written. While many of the sentences are long, they're packed with information..."},
    "annotator_5":
      {
       "guess":"Human-Generated",
       "confidence":5,
       "comment":"Although the author tries to report only facts, the final sentence..."
      },
    "expert_majority_vote": "Human-written"
   },
}

```




## Citation Information
If you use this dataset, please cite it as follows:
```
@misc{russell2025peoplefrequentlyusechatgpt,
      title={People who frequently use ChatGPT for writing tasks are accurate and robust detectors of AI-generated text}, 
      author={Jenna Russell and Marzena Karpinska and Mohit Iyyer},
      year={2025},
      eprint={2501.15654},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2501.15654}, 
}
```
